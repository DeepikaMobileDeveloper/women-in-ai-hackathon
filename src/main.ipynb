{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive RAG with Milvus and LangChain\n",
    "This notebook contains an implementation of RAG with Milvus, LangChain, and HuggingFace. Its purpose is to provide you with a starting point for coding, if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load (quantized) Phi-4 for Apple Sillicon hardware\n",
    "Using default `transformers` implementation is too slow on my MacBook (even though it is set to use `mps` device). Hence, I use the `mlx-lm` library.\n",
    "\n",
    "For users on non-Apple Sillicon hardware, load your LLM as normal with `transformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97da84550f5f4a76b3b601966aaaf27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b6c7534cbb46629415dd9a888bcb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939119b512b74efc81fcde2716e03a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/49.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467f98a980994839aad1e2089a252557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d876956c494e55b1dda726445a52a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46a7ecc9cb348dd91bbfb92d5fc6c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af3579744764c75b73fa3d09fb1f492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/464 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9bdac1728c404092f9f4fc8a0c6f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/917k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbde7eb2e04844d28c506a27039141d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a7808856504b86888a18ae15a11e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.61M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlx_lm import load\n",
    "model, tokenizer = load(\"mlx-community/phi-4-4bit\") # <= replace with smaller model depending on WiFi bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.mlx_pipeline import MLXPipeline\n",
    "from langchain_community.chat_models.mlx import ChatMLX\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = MLXPipeline(\n",
    "    model=model, tokenizer=tokenizer, pipeline_kwargs={\"max_tokens\": 1024, \"temp\": 0.1}\n",
    ")\n",
    "\n",
    "chat = ChatMLX(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test language model\n",
    "Ignore the warning, which is due to a breaking change in one of the libraries used in the past couple of weeks. That's why I pin `mlx-lm==0.20.6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Specifying sampling arguments to ``generate_step`` is deprecated. Pass in a ``sampler`` instead.\n",
      "As an AI, I can provide some perspectives on the question of what happens when an unstoppable force meets an immovable object, but it's important to note that this is a classic paradox that doesn't have a definitive answer within the framework of classical physics.\n",
      "\n",
      "1. **Logical Paradox**: The scenario is a logical paradox because the definitions of an \"unstoppable force\" and an \"immovable object\" are mutually exclusive. If a force is truly unstoppable, it cannot be stopped by any object, no matter how immovable. Conversely, if an object is truly immovable, no force can move it.\n",
      "\n",
      "2. **Philosophical Interpretation**: Philosophically, this paradox can be used to explore the limits of language and logic. It challenges our understanding of concepts like infinity, absolute power, and the nature of reality.\n",
      "\n",
      "3. **Theoretical Physics**: In theoretical physics, the laws of nature as we understand them do not allow for the existence of such absolutes. Forces and objects are subject to the laws of physics, which include limitations and interactions that prevent such paradoxical situations.\n",
      "\n",
      "4. **Creative Exploration**: In literature and popular culture, this paradox is often used as a plot device or a thought experiment to explore themes of conflict, power, and the nature of reality.\n",
      "\n",
      "Ultimately, the question is more about exploring the boundaries of logic and language than about a scenario that could occur in the physical world.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"What happens when an unstoppable force meets an immovable object?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "res = chat.invoke(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a WebBaseLoader instance to load documents from web sources\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\n",
    "        \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "        \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "# Load documents from web sources using the loader\n",
    "documents = loader.load()\n",
    "# Initialize a RecursiveCharacterTextSplitter for splitting text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "\n",
    "# Split the documents into chunks using the text_splitter\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Let's take a look at the first document\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build naive RAG with Milvus and LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "embeddings = SentenceTransformerEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_milvus import Milvus, Zilliz\n",
    "\n",
    "vectorstore = Milvus.from_documents(  # or Zilliz.from_documents\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": \"./milvus_demo.db\",\n",
    "    },\n",
    "    drop_old=True,  # Drop the old Milvus collection if it exists\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency: recent events have higher scores\n",
      "Importance: distinguish mundane from core memories. Ask LM directly.\n",
      "Relevance: based on how related it is to the current situation / query.\n",
      "\n",
      "\n",
      "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
      "\n",
      "Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\n",
      "\n",
      "\n",
      "Planning & Reacting: translate the reflections and the environment information into actions\n",
      "\n",
      "Planning is essentially in order to optimize believability at the moment vs in time.\n",
      "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
      "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
      "Environment information is present...\n"
     ]
    }
   ],
   "source": [
    "query = \"What is self-reflection of an AI Agent?\"\n",
    "res = vectorstore.similarity_search(query, k=1)\n",
    "print(res[0].page_content[0:1024] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra LangChain stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define the prompt template for generating AI responses\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: You are an AI assistant, and provides answers to questions by using fact based and statistical information when possible.\n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "# Create a PromptTemplate instance with the defined template and input variables\n",
    "prompt = PromptTemplate(\n",
    "    template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "# Convert the vector store to a retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "# Define a function to format the retrieved documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Specifying sampling arguments to ``generate_step`` is deprecated. Pass in a ``sampler`` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Self-reflection in AI agents refers to the capability of an agent to evaluate and refine its past actions and decisions to improve future performance. This process involves dynamic memory and self-reflection mechanisms that allow the agent to identify inefficiencies or errors in its previous trajectories and make necessary adjustments.\\n\\nIn the Reflexion framework (Shinn & Labash, 2023), self-reflection is achieved by incorporating two-shot examples into the agent's working memory. These examples consist of pairs of failed trajectories and ideal reflections that guide future changes in the plan. The agent can store up to three reflections to use as context when querying a language model (LLM).\\n\\nThe heuristic function in Reflexion determines when a trajectory is inefficient or contains hallucinations, prompting the agent to reset the environment and start a new trial if necessary. Inefficient planning refers to trajectories that take too long without success, while hallucination is defined as encountering a sequence of consecutive identical actions leading to the same observation.\\n\\nBy integrating self-reflection, AI agents can iteratively improve their reasoning skills and decision-making processes, making them more effective in real-world tasks where trial and error are common.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the RAG (Retrieval-Augmented Generation) chain for AI response generation\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# rag_chain.get_graph().print_ascii()\n",
    "\n",
    "# Invoke the RAG chain with a specific question and retrieve the response\n",
    "res = rag_chain.invoke(query)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-reflection in AI agents refers to the capability of an agent to evaluate and refine its past actions and decisions to improve future performance. This process involves dynamic memory and self-reflection mechanisms that allow the agent to identify inefficiencies or errors in its previous trajectories and make necessary adjustments.\n",
      "\n",
      "In the Reflexion framework (Shinn & Labash, 2023), self-reflection is achieved by incorporating two-shot examples into the agent's working memory. These examples consist of pairs of failed trajectories and ideal reflections that guide future changes in the plan. The agent can store up to three reflections to use as context when querying a language model (LLM).\n",
      "\n",
      "The heuristic function in Reflexion determines when a trajectory is inefficient or contains hallucinations, prompting the agent to reset the environment and start a new trial if necessary. Inefficient planning refers to trajectories that take too long without success, while hallucination is defined as encountering a sequence of consecutive identical actions leading to the same observation.\n",
      "\n",
      "By integrating self-reflection, AI agents can iteratively improve their reasoning skills and decision-making processes, making them more effective in real-world tasks where trial and error are common.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You have successfully built and run a RAG pipeline using Milvus, Hugging Face, and LangChain libraries!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
